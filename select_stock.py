from __future__ import annotations

import argparse
import importlib
import json
import logging
import sys
from pathlib import Path
from typing import Any, Dict, Iterable, List, Tuple

import pandas as pd
import numpy as np

# ---------- æ—¥å¿— ----------
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[
        logging.StreamHandler(sys.stdout),
        # å°†æ—¥å¿—å†™å…¥æ–‡ä»¶
        logging.FileHandler("select_results.log", encoding="utf-8"),
    ],
)
logger = logging.getLogger("select")


# ---------- ä»·æ ¼å»ºè®®è®¡ç®— ----------
# æ­¤å‡½æ•°å·²ç§»åŠ¨åˆ° Selector.py

def format_stock_with_prices(stock_info: Dict[str, Any]) -> str:
    """
    æ ¼å¼åŒ–è‚¡ç¥¨ä¿¡æ¯ï¼ŒåŒ…å«ä»·æ ¼å»ºè®®
    """
    stock_code = stock_info['code']
    score = stock_info.get('score')
    prices = stock_info['prices']
    risk_reward_ratio = stock_info.get('risk_reward_ratio', 0)
    
    if prices.get("entry_price", 0) == 0:
        return f"{stock_code} (æ— ä»·æ ¼æ•°æ®)"
    
    # è®¡ç®—é¢„æœŸæ”¶ç›Šå’Œé£é™©æ¯”
    potential_return = (prices["exit_price"] - prices["entry_price"]) / prices["entry_price"] * 100
    potential_loss = (prices["entry_price"] - prices["stop_loss"]) / prices["entry_price"] * 100
    
    score_str = f"| å¾—åˆ†: {score:.2f} " if score is not None else ""

    return (f"{stock_code} {score_str}| "
            f"åŸºäºæ—¥æœŸ: {prices['actual_date']} | "
            f"å…¥åœº: Â¥{prices['entry_price']} | "
            f"ç¦»åœº: Â¥{prices['exit_price']} | " 
            f"æ­¢æŸ: Â¥{prices['stop_loss']} | "
            f"é¢„æœŸæ”¶ç›Š: {potential_return:+.1f}% | "
            f"é£é™©: {potential_loss:.1f}% | "
            f"æ”¶ç›Šé£é™©æ¯”: {risk_reward_ratio:.1f}")


# ---------- å·¥å…· ----------

def load_data(data_dir: Path, codes: Iterable[str]) -> Dict[str, pd.DataFrame]:
    frames: Dict[str, pd.DataFrame] = {}
    for code in codes:
        fp = data_dir / f"{code}.csv"
        if not fp.exists():
            logger.warning("%s ä¸å­˜åœ¨ï¼Œè·³è¿‡", fp.name)
            continue
        df = pd.read_csv(fp, parse_dates=["date"]).sort_values("date")
        
        # ä¿®å¤ 'volume.1' -> 'amount' çš„é—®é¢˜
        if 'volume.1' in df.columns:
            if 'amount' in df.columns:
                df = df.drop(columns=['amount'])
            df = df.rename(columns={'volume.1': 'amount'})
            
        # é˜²å¾¡æ€§æ£€æŸ¥ï¼šç¡®ä¿ amount åˆ—å­˜åœ¨
        if 'amount' not in df.columns:
            df['amount'] = 0

        frames[code] = df
    return frames


def load_config(cfg_path: Path) -> List[Dict[str, Any]]:
    if not cfg_path.exists():
        logger.error("é…ç½®æ–‡ä»¶ %s ä¸å­˜åœ¨", cfg_path)
        sys.exit(1)
    with cfg_path.open(encoding="utf-8") as f:
        cfg_raw = json.load(f)

    # å…¼å®¹ä¸‰ç§ç»“æ„ï¼šå•å¯¹è±¡ã€å¯¹è±¡æ•°ç»„ã€æˆ–å¸¦ selectors é”®
    if isinstance(cfg_raw, list):
        cfgs = cfg_raw
    elif isinstance(cfg_raw, dict) and "selectors" in cfg_raw:
        cfgs = cfg_raw["selectors"]
    else:
        cfgs = [cfg_raw]

    if not cfgs:
        logger.error("configs.json æœªå®šä¹‰ä»»ä½• Selector")
        sys.exit(1)

    return cfgs


def instantiate_selector(cfg: Dict[str, Any]):
    """åŠ¨æ€åŠ è½½ Selector ç±»å¹¶å®ä¾‹åŒ–"""
    cls_name: str | None = cfg.get("class")
    if not cls_name:
        raise ValueError("ç¼ºå°‘ class å­—æ®µ")

    try:
        module = importlib.import_module("Selector")
        cls = getattr(module, cls_name)
    except (ModuleNotFoundError, AttributeError) as e:
        raise ImportError(f"æ— æ³•åŠ è½½ Selector.{cls_name}: {e}") from e

    params = cfg.get("params", {})
    return cfg.get("alias", cls_name), cls(**params)


# ---------- ä¸»å‡½æ•° ----------

def main():
    parser = argparse.ArgumentParser(description="Run selectors defined in configs.json")
    parser.add_argument("--data-dir", default="./data", help="CSV è¡Œæƒ…ç›®å½•")
    parser.add_argument(
        "--config", type=Path, default=Path("./configs.json"), help="ç­–ç•¥é…ç½®æ–‡ä»¶"
    )
    parser.add_argument("--date", type=str, required=False, help="é€‰è‚¡æ—¥æœŸï¼Œæ ¼å¼ YYYY-MM-DD")
    parser.add_argument("--tickers", default="all", help="'all' æˆ–é€—å·åˆ†éš”è‚¡ç¥¨ä»£ç åˆ—è¡¨")
    parser.add_argument("--log-file", type=str, default=None, help="æŒ‡å®šæ—¥å¿—è¾“å‡ºæ–‡ä»¶è·¯å¾„")

    args = parser.parse_args()
    
    # --- æ—¥å¿—é…ç½® ---
    # ç§»é™¤æ‰€æœ‰ç°æœ‰çš„å¤„ç†å™¨
    for handler in logger.handlers[:]:
        logger.removeHandler(handler)

    # æ ¹æ®æ˜¯å¦å­˜åœ¨ --log-file å‚æ•°æ¥å†³å®šè¾“å‡ºç›®æ ‡
    if args.log_file:
        # è¾“å‡ºåˆ°æ–‡ä»¶
        handler = logging.FileHandler(args.log_file, mode='a', encoding='utf-8')
        handler.setFormatter(logging.Formatter('%(message)s')) # å›æµ‹æ—¶åªè®°å½•æ ¸å¿ƒä¿¡æ¯
    else:
        # è¾“å‡ºåˆ°æ§åˆ¶å°
        handler = logging.StreamHandler(sys.stdout)
        handler.setFormatter(logging.Formatter('%(asctime)s [%(levelname)s] %(message)s'))
    
    logger.addHandler(handler)
    logger.propagate = False

    # --- åŠ è½½è¡Œæƒ… ---
    data_dir = Path(args.data_dir)
    if not data_dir.exists():
        logger.error("æ•°æ®ç›®å½• %s ä¸å­˜åœ¨", data_dir)
        sys.exit(1)

    codes = (
        [f.stem for f in data_dir.glob("*.csv")]
        if args.tickers.lower() == "all"
        else [c.strip() for c in args.tickers.split(",") if c.strip()]
    )
    if not codes:
        logger.error("è‚¡ç¥¨æ± ä¸ºç©ºï¼")
        sys.exit(1)

    data = load_data(data_dir, codes)
    if not data:
        logger.error("æ•°æ®ç›®å½• %s ä¸ºç©ºï¼Œè¯·å…ˆè¿è¡Œ fetch_kline.py", data_dir)
        sys.exit(1)

    # --- ç¡®å®šäº¤æ˜“æ—¥ ---
    if args.date:
        try:
            trade_date = pd.to_datetime(args.date)
        except ValueError:
            logger.error("æ—¥æœŸæ ¼å¼ä¸æ­£ç¡®ï¼Œè¯·ä½¿ç”¨ YYYY-MM-DD æ ¼å¼")
            sys.exit(1)
    else:
        trade_date = max(df["date"].max() for df in data.values())
        if not args.log_file: # åªæœ‰åœ¨éå›æµ‹æ¨¡å¼ä¸‹æ‰æ‰“å°
            logger.info("æœªæŒ‡å®š --dateï¼Œä½¿ç”¨æœ€è¿‘æ—¥æœŸ %s", trade_date.date())

    # --- åŠ è½½ç­–ç•¥é…ç½® ---
    try:
        with open(args.config, "r", encoding="utf-8") as f:
            config_data = json.load(f)
        # ç¡®ä¿æˆ‘ä»¬è·å–çš„æ˜¯ 'selectors' é”®ä¸‹çš„åˆ—è¡¨
        selector_cfgs = config_data.get("selectors", [])
        if not selector_cfgs:
            raise ValueError("é…ç½®æ–‡ä»¶ä¸­æœªæ‰¾åˆ° 'selectors' åˆ—è¡¨æˆ–åˆ—è¡¨ä¸ºç©º")
    except (FileNotFoundError, json.JSONDecodeError, ValueError) as e:
        logger.error("åŠ è½½æˆ–è§£æé…ç½®æ–‡ä»¶ %s æ—¶å‡ºé”™: %s", args.config, e)
        sys.exit(1)

    # --- é€ä¸ª Selector è¿è¡Œ ---
    for cfg in selector_cfgs:
        if not isinstance(cfg, dict) or cfg.get("activate", True) is False:
            continue
        try:
            alias, selector = instantiate_selector(cfg)
        except Exception as e:
            logger.error("è·³è¿‡é…ç½® %sï¼š%s", cfg, e)
            continue

        picks = selector.select(trade_date, data)

        # å°†ç»“æœå†™å…¥æ—¥å¿—ï¼ŒåŒæ—¶è¾“å‡ºåˆ°æ§åˆ¶å°
        logger.info("")
        logger.info("============== é€‰è‚¡ç»“æœ [%s] ==============", alias)
        logger.info("äº¤æ˜“æ—¥: %s", trade_date.date())
        logger.info("ç¬¦åˆæ¡ä»¶è‚¡ç¥¨æ•°: %d", len(picks))
        
        if picks:
            logger.info("ğŸ“‹ è¯¦ç»†äº¤æ˜“å»ºè®®:")
            for pick in picks:
                # Selector å·²è¿”å›æ‰€æœ‰éœ€è¦çš„ä¿¡æ¯
                log_line = format_stock_with_prices(pick)
                logger.info("   %s", log_line)
            
        else:
            logger.info("æ— ç¬¦åˆæ¡ä»¶è‚¡ç¥¨")


if __name__ == "__main__":
    main()
